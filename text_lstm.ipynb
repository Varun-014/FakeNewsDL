{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.layers import MaxPool1D, LSTM, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Body'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
       "      <td>four ways bob corker skewered donald trump</td>\n",
       "      <td>image copyright getty images\\non sunday mornin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
       "      <td>linklater's war veteran comedy speaks to moder...</td>\n",
       "      <td>london (reuters) - “last flag flying”, a comed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
       "      <td>trump’s fight with corker jeopardizes his legi...</td>\n",
       "      <td>the feud broke into public view last week when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
       "      <td>egypt's cheiron wins tie-up with pemex for mex...</td>\n",
       "      <td>mexico city (reuters) - egypt’s cheiron holdin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
       "      <td>jason aldean opens 'snl' with vegas tribute</td>\n",
       "      <td>country singer jason aldean, who was performin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs  \\\n",
       "0  http://www.bbc.com/news/world-us-canada-414191...   \n",
       "1  https://www.reuters.com/article/us-filmfestiva...   \n",
       "2  https://www.nytimes.com/2017/10/09/us/politics...   \n",
       "3  https://www.reuters.com/article/us-mexico-oil-...   \n",
       "4  http://www.cnn.com/videos/cnnmoney/2017/10/08/...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0         four ways bob corker skewered donald trump   \n",
       "1  linklater's war veteran comedy speaks to moder...   \n",
       "2  trump’s fight with corker jeopardizes his legi...   \n",
       "3  egypt's cheiron wins tie-up with pemex for mex...   \n",
       "4        jason aldean opens 'snl' with vegas tribute   \n",
       "\n",
       "                                                Body  Label  \n",
       "0  image copyright getty images\\non sunday mornin...      1  \n",
       "1  london (reuters) - “last flag flying”, a comed...      1  \n",
       "2  the feud broke into public view last week when...      1  \n",
       "3  mexico city (reuters) - egypt’s cheiron holdin...      1  \n",
       "4  country singer jason aldean, who was performin...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Headline'] = df['Headline'].str.lower()\n",
    "df['Body'] = df['Body'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuations(text):\n",
    "    punctuations = set(string.punctuation)\n",
    "    text = str(text)\n",
    "    # return text.translate(str.maketrans('', '', punctuations))\n",
    "    return \" \".join([word for word in text.split() if word not in punctuations])\n",
    "\n",
    "df['Headline'] = df['Headline'].apply(lambda x: remove_punctuations(x))\n",
    "df['Body'] = df['Body'].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "\n",
    "df['Headline'] = df['Headline'].apply(lambda x: remove_stopwords(x))\n",
    "df['Body'] = df['Body'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_spl_chars(text):\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['Headline'] = df['Headline'].apply(lambda x: remove_spl_chars(x))\n",
    "df['Body'] = df['Body'].apply(lambda x: remove_spl_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "def stem(text):\n",
    "    stemmed_sentence = \" \".join(stemmer.stem(word) for word in text.split())\n",
    "    return stemmed_sentence\n",
    "\n",
    "df['Headline'] = df['Headline'].apply(lambda x: stem(x))\n",
    "df['Body'] = df['Body'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "for i in range(3988):\n",
    "    texts.append(df['Body'][i])\n",
    "    labels.append(df['Label'][i])\n",
    "\n",
    "print(len(texts))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_vect(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vector'] = df['Body'].apply(lambda text: prep_vect(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vector'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.vector.values, df.Label, test_size=0.2, random_state=2022, stratify=df.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here x_train is not a native 2D numpy array but a numpy array within a numpy array\n",
    "x_train_2d = np.stack(x_train) \n",
    "x_test_2d = np.stack(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[300])\n",
    "    # layer = Embedding(max_words,100,input_length=300)(inputs)\n",
    "    layer = Reshape((1, 300))(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 300)]             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 300)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                93440     \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               16640     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110337 (431.00 KB)\n",
      "Trainable params: 110337 (431.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model_lstm = RNN()\n",
    "model_lstm.summary()\n",
    "model_lstm.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above model in the shape of input for LSTM (batch_size, time_step, number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 27ms/step - loss: 0.6905 - accuracy: 0.5301 - val_loss: 0.6946 - val_accuracy: 0.4828\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5371 - val_loss: 0.6954 - val_accuracy: 0.4828\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.5371 - val_loss: 0.6874 - val_accuracy: 0.4828\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6773 - accuracy: 0.5388 - val_loss: 0.6804 - val_accuracy: 0.4828\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.5831 - val_loss: 0.6563 - val_accuracy: 0.6583\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.7102 - val_loss: 0.6179 - val_accuracy: 0.7461\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.7753 - val_loss: 0.5614 - val_accuracy: 0.7868\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7969 - val_loss: 0.5009 - val_accuracy: 0.8339\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.8203 - val_loss: 0.4673 - val_accuracy: 0.7774\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8436 - val_loss: 0.3980 - val_accuracy: 0.8495\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8589 - val_loss: 0.3562 - val_accuracy: 0.8621\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8739 - val_loss: 0.3239 - val_accuracy: 0.8683\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.8795 - val_loss: 0.2987 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2820 - accuracy: 0.8854 - val_loss: 0.2992 - val_accuracy: 0.8871\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.8906 - val_loss: 0.2644 - val_accuracy: 0.8871\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2534 - accuracy: 0.8913 - val_loss: 0.2621 - val_accuracy: 0.8997\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2347 - accuracy: 0.9063 - val_loss: 0.2566 - val_accuracy: 0.8997\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2248 - accuracy: 0.9070 - val_loss: 0.2314 - val_accuracy: 0.9185\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2178 - accuracy: 0.9101 - val_loss: 0.2221 - val_accuracy: 0.9154\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2045 - accuracy: 0.9199 - val_loss: 0.2171 - val_accuracy: 0.9248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f2fe6e9480>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(x_train_2d,y_train, batch_size=128, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(x_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in y_pred:\n",
    "    if p[0] >= 0.5:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
